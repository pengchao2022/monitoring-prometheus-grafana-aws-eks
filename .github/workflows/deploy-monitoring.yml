name: Deploy Monitoring Stack to EKS

on:
  push:
    branches: [ main ]
  workflow_dispatch:

env:
  CLUSTER_NAME: ${{ secrets.EKS_CLUSTER_NAME }}
  AWS_REGION: ${{ secrets.AWS_REGION || 'us-east-1' }}

permissions:
  id-token: write
  contents: read

jobs:
  deploy:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Debug - Check files in workspace
      run: |
        echo "=== å½“å‰å·¥ä½œç›®å½•æ–‡ä»¶ ==="
        pwd
        ls -la
        echo ""
        echo "=== æ£€æŸ¥ç›‘æ§é…ç½®æ–‡ä»¶ ==="
        find . -name "*.yaml" -o -name "*.yml" | head -10
        echo ""
        echo "=== æ£€æŸ¥kubernetesç›®å½•ç»“æ„ ==="
        if [ -d "kubernetes" ]; then
          echo "kubernetesç›®å½•å­˜åœ¨"
          find kubernetes/ -name "*.yaml" -o -name "*.yml"
        fi
        echo ""
        echo "=== æ£€æŸ¥chartsç›®å½• ==="
        if [ -d "charts" ]; then
          echo "chartsç›®å½•å­˜åœ¨"
          ls -la charts/kube-prometheus-stack/
        fi

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Set up kubectl and helm
      run: |
        curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
        sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl
        curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash

    - name: Update kubeconfig
      run: |
        aws eks update-kubeconfig --region ${{ env.AWS_REGION }} --name ${{ env.CLUSTER_NAME }}

    - name: Create monitoring namespace
      run: |
        kubectl create namespace monitoring --dry-run=client -o yaml | kubectl apply -f -

    - name: Add prometheus-community helm repository
      run: |
        helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
        helm repo update

    - name: Install kube-prometheus-stack with custom values
      run: |
        echo "=== ä½¿ç”¨Helmå®‰è£…kube-prometheus-stackï¼ˆç¦ç”¨node-exporterï¼‰==="
        
        if [ -f "charts/kube-prometheus-stack/values-alb.yaml" ]; then
          echo "ä½¿ç”¨è‡ªå®šä¹‰values-alb.yamlæ–‡ä»¶å®‰è£…ï¼ˆç¦ç”¨node-exporterï¼‰..."
          helm upgrade --install kube-prometheus-stack prometheus-community/kube-prometheus-stack \
            -n monitoring \
            --create-namespace \
            -f charts/kube-prometheus-stack/values-alb.yaml \
            --set nodeExporter.enabled=false
        else
          echo "ä½¿ç”¨é»˜è®¤é…ç½®å®‰è£…ï¼ˆç¦ç”¨node-exporterï¼‰..."
          helm upgrade --install kube-prometheus-stack prometheus-community/kube-prometheus-stack \
            -n monitoring \
            --create-namespace \
            --set nodeExporter.enabled=false
        fi

    - name: Clean up existing Node Exporter
      run: |
        echo "=== æ¸…ç†ç°æœ‰çš„Node Exporter ==="
        # åˆ é™¤Helmå¯èƒ½åˆ›å»ºçš„node-exporter
        kubectl delete daemonset kube-prometheus-stack-prometheus-node-exporter -n monitoring --ignore-not-found=true
        # åˆ é™¤pendingçš„pods
        kubectl delete pod -n monitoring -l app.kubernetes.io/name=prometheus-node-exporter --ignore-not-found=true

    - name: Deploy custom Node Exporter
      run: |
        echo "=== éƒ¨ç½²æ‚¨æœ¬åœ°çš„Node Exporter DaemonSet ==="
        
        if [ -f "kubernetes/node-exporter/daemonset-limited.yaml" ]; then
          echo "éƒ¨ç½²æ‚¨æœ¬åœ°çš„Node Exporter..."
          kubectl apply -f kubernetes/node-exporter/daemonset-limited.yaml -n monitoring
          echo "âœ… æœ¬åœ°Node Exporteréƒ¨ç½²å®Œæˆ"
        else
          echo "âŒ æœ¬åœ°daemonset-limited.yamlæ–‡ä»¶ä¸å­˜åœ¨"
          exit 1
        fi

    - name: Deploy additional Kubernetes manifests
      run: |
        echo "=== éƒ¨ç½²é¢å¤–çš„Kubernetesæ¸…å•æ–‡ä»¶ ==="
        
        # éƒ¨ç½²network policies
        if [ -f "kubernetes/network-policies/monitoring-network-policy.yaml" ]; then
          echo "éƒ¨ç½²ç½‘ç»œç­–ç•¥..."
          kubectl apply -f kubernetes/network-policies/monitoring-network-policy.yaml -n monitoring || echo "NetworkPolicyéƒ¨ç½²å¤±è´¥ï¼Œè·³è¿‡"
        fi
        
        # éƒ¨ç½²Ingressèµ„æº - ä½¿ç”¨æ‚¨æœ¬åœ°çš„Ingressæ–‡ä»¶
        echo "éƒ¨ç½²Ingressèµ„æº..."
        kubectl apply -f kubernetes/ingress/ -n monitoring

    - name: Wait for ALB and get address
      id: get_elb
      run: |
        echo "ç­‰å¾…ALBåˆ›å»º..."
        sleep 60
        
        # æ£€æŸ¥æ‰€æœ‰èµ„æºçŠ¶æ€
        echo "=== æ£€æŸ¥éƒ¨ç½²çŠ¶æ€ ==="
        kubectl get pods,svc,ingress -n monitoring
        
        # è·å–ELBåœ°å€
        ELB_ADDRESS=$(kubectl get ingress -n monitoring -o jsonpath='{.items[0].status.loadBalancer.ingress[0].hostname}')
        
        if [ -z "$ELB_ADDRESS" ]; then
          echo "âŒ æ— æ³•è·å–ELBåœ°å€ï¼Œç­‰å¾…é‡è¯•..."
          sleep 30
          ELB_ADDRESS=$(kubectl get ingress -n monitoring -o jsonpath='{.items[0].status.loadBalancer.ingress[0].hostname}')
        fi
        
        echo "ELB_ADDRESS=$ELB_ADDRESS" >> $GITHUB_OUTPUT
        echo "ELBåœ°å€: $ELB_ADDRESS"

    - name: Configure Grafana for subpath support
      run: |
        echo "=== é…ç½®Grafanaæ”¯æŒå­è·¯å¾„ ==="
        
        ELB_ADDRESS="${{ steps.get_elb.outputs.ELB_ADDRESS }}"
        
        if [ -n "$ELB_ADDRESS" ]; then
          echo "é…ç½®Grafanaä½¿ç”¨ALBåœ°å€: $ELB_ADDRESS"
          
          # ä½¿ç”¨æ­£ç¡®çš„URLæ ¼å¼ï¼Œé¿å…%ç¬¦å·é—®é¢˜
          kubectl patch configmap kube-prometheus-stack-grafana -n monitoring --type=merge \
            --patch '{"data":{"grafana.ini":"[server]\ndomain = '"$ELB_ADDRESS"'\nroot_url = http://'"$ELB_ADDRESS"'/grafana/\nserve_from_sub_path = true\n"}}'
          
          # é‡å¯Grafana
          echo "é‡å¯Grafana Pod..."
          kubectl rollout restart deployment kube-prometheus-stack-grafana -n monitoring
          
          # ç­‰å¾…é‡å¯
          echo "ç­‰å¾…Grafanaé‡å¯..."
          sleep 60
          
          # æ£€æŸ¥çŠ¶æ€å’Œæ—¥å¿—
          echo "Grafana PodçŠ¶æ€:"
          kubectl get pod -n monitoring -l app.kubernetes.io/name=grafana
          
          echo "Grafana Podæ—¥å¿—:"
          kubectl logs -n monitoring -l app.kubernetes.io/name=grafana --tail=10
          
          echo "âœ… Grafanaå­è·¯å¾„é…ç½®å®Œæˆ"
        else
          echo "âŒ æ— æ³•è·å–ELBåœ°å€ï¼Œè·³è¿‡Grafanaé…ç½®"
        fi

    - name: Update Prometheus and Alertmanager external URLs
      run: |
        echo "=== æ›´æ–°Prometheuså’ŒAlertmanagerçš„å¤–éƒ¨URL ==="
        
        ELB_ADDRESS="${{ steps.get_elb.outputs.ELB_ADDRESS }}"
        
        if [ -n "$ELB_ADDRESS" ]; then
          # æ›´æ–°Prometheus externalUrl
          kubectl get prometheus kube-prometheus-stack-prometheus -n monitoring && \
          kubectl patch prometheus kube-prometheus-stack-prometheus -n monitoring --type='merge' \
            -p='{"spec":{"externalUrl":"http://'$ELB_ADDRESS'/prometheus","routePrefix":"/prometheus"}}' || \
          echo "Prometheusèµ„æºä¸å­˜åœ¨ï¼Œè·³è¿‡"
          
          # æ›´æ–°Alertmanager externalUrl
          kubectl get alertmanager kube-prometheus-stack-alertmanager -n monitoring && \
          kubectl patch alertmanager kube-prometheus-stack-alertmanager -n monitoring --type='merge' \
            -p='{"spec":{"externalUrl":"http://'$ELB_ADDRESS'/alertmanager","routePrefix":"/alertmanager"}}' || \
          echo "Alertmanagerèµ„æºä¸å­˜åœ¨ï¼Œè·³è¿‡"
          
          echo "âœ… å¤–éƒ¨URLæ›´æ–°å®Œæˆ"
        else
          echo "âŒ æ— æ³•è·å–ELBåœ°å€ï¼Œè·³è¿‡URLæ›´æ–°"
        fi

    - name: Restart monitoring services
      run: |
        echo "=== é‡å¯ç›‘æ§æœåŠ¡ä»¥åº”ç”¨é…ç½® ==="
        # é‡å¯Prometheusï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        kubectl delete pod -n monitoring -l app.kubernetes.io/name=prometheus --ignore-not-found=true || echo "æ²¡æœ‰Prometheus Pod"
        # é‡å¯Alertmanagerï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        kubectl delete pod -n monitoring -l app.kubernetes.io/name=alertmanager --ignore-not-found=true || echo "æ²¡æœ‰Alertmanager Pod"
        sleep 30

    - name: Output access information
      run: |
        echo "=========================================="
        echo "ğŸš€ ç›‘æ§æ ˆéƒ¨ç½²å®Œæˆï¼"
        echo "=========================================="
        echo ""
        echo "é›†ç¾¤: ${{ env.CLUSTER_NAME }}"
        echo "åŒºåŸŸ: ${{ env.AWS_REGION }}"
        echo ""
        echo "ä½¿ç”¨ä»¥ä¸‹URLè®¿é—®ç›‘æ§é¢æ¿ï¼š"
        echo "ğŸ“Š Prometheus: http://${{ steps.get_elb.outputs.ELB_ADDRESS }}/prometheus"
        echo "ğŸ“ˆ Grafana: http://${{ steps.get_elb.outputs.ELB_ADDRESS }}/grafana"
        echo "ğŸš¨ Alertmanager: http://${{ steps.get_elb.outputs.ELB_ADDRESS }}/alertmanager"
        echo ""
        echo "Grafanaé»˜è®¤å‡­æ®ï¼š"
        echo "ç”¨æˆ·å: admin"
        echo "å¯†ç : prom-operator"
        echo ""
        echo "å¦‚æœGrafanaé¡µé¢æ˜¾ç¤ºç©ºç™½ï¼Œè¯·ç­‰å¾…å‡ åˆ†é’Ÿè®©é…ç½®ç”Ÿæ•ˆ"

    - name: Final verification
      run: |
        echo "=== æœ€ç»ˆéªŒè¯ ==="
        echo "=== PodçŠ¶æ€ ==="
        kubectl get pods -n monitoring -o wide
        echo ""
        echo "=== Node Exporteråˆ†å¸ƒ ==="
        kubectl get pods -n monitoring -l app=node-exporter-limited -o wide
        echo ""
        echo "=== Ingressè¯¦æƒ… ==="
        kubectl get ingress -n monitoring -o wide
        echo ""
        echo "=== Grafanaé…ç½®æ£€æŸ¥ ==="
        kubectl get configmap kube-prometheus-stack-grafana -n monitoring -o jsonpath='{.data.grafana\.ini}' | grep -A 3 "\\[server\\]"