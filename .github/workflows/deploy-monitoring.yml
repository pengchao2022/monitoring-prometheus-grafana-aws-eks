name: Deploy Monitoring Stack to EKS

on:
  push:
    branches: [ main ]
  workflow_dispatch:

env:
  CLUSTER_NAME: ${{ secrets.EKS_CLUSTER_NAME }}
  AWS_REGION: ${{ secrets.AWS_REGION || 'us-east-1' }}

permissions:
  id-token: write
  contents: read

jobs:
  deploy:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Debug - Check files in workspace
      run: |
        echo "=== 当前工作目录文件 ==="
        pwd
        ls -la
        echo ""
        echo "=== 检查监控配置文件 ==="
        find . -name "*.yaml" -o -name "*.yml" | head -10
        echo ""
        echo "=== 检查kubernetes目录结构 ==="
        if [ -d "kubernetes" ]; then
          echo "kubernetes目录存在"
          find kubernetes/ -name "*.yaml" -o -name "*.yml"
        fi
        echo ""
        echo "=== 检查charts目录 ==="
        if [ -d "charts" ]; then
          echo "charts目录存在"
          ls -la charts/kube-prometheus-stack/
        fi

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Set up kubectl and helm
      run: |
        curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
        sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl
        curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash

    - name: Update kubeconfig
      run: |
        aws eks update-kubeconfig --region ${{ env.AWS_REGION }} --name ${{ env.CLUSTER_NAME }}

    - name: Create monitoring namespace
      run: |
        kubectl create namespace monitoring --dry-run=client -o yaml | kubectl apply -f -

    - name: Add prometheus-community helm repository
      run: |
        helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
        helm repo update

    - name: Install kube-prometheus-stack with custom values
      run: |
        echo "=== 使用Helm安装kube-prometheus-stack（禁用node-exporter）==="
        
        if [ -f "charts/kube-prometheus-stack/values-alb.yaml" ]; then
          echo "使用自定义values-alb.yaml文件安装（禁用node-exporter）..."
          helm upgrade --install kube-prometheus-stack prometheus-community/kube-prometheus-stack \
            -n monitoring \
            --create-namespace \
            -f charts/kube-prometheus-stack/values-alb.yaml \
            --set nodeExporter.enabled=false
        else
          echo "使用默认配置安装（禁用node-exporter）..."
          helm upgrade --install kube-prometheus-stack prometheus-community/kube-prometheus-stack \
            -n monitoring \
            --create-namespace \
            --set nodeExporter.enabled=false
        fi

    - name: Clean up existing Node Exporter
      run: |
        echo "=== 清理现有的Node Exporter ==="
        # 删除Helm可能创建的node-exporter
        kubectl delete daemonset kube-prometheus-stack-prometheus-node-exporter -n monitoring --ignore-not-found=true
        # 删除pending的pods
        kubectl delete pod -n monitoring -l app.kubernetes.io/name=prometheus-node-exporter --ignore-not-found=true

    - name: Deploy custom Node Exporter
      run: |
        echo "=== 部署您本地的Node Exporter DaemonSet ==="
        
        if [ -f "kubernetes/node-exporter/daemonset-limited.yaml" ]; then
          echo "部署您本地的Node Exporter..."
          kubectl apply -f kubernetes/node-exporter/daemonset-limited.yaml -n monitoring
          echo "✅ 本地Node Exporter部署完成"
        else
          echo "❌ 本地daemonset-limited.yaml文件不存在"
          exit 1
        fi

    - name: Deploy additional Kubernetes manifests
      run: |
        echo "=== 部署额外的Kubernetes清单文件 ==="
        
        # 部署network policies
        if [ -f "kubernetes/network-policies/monitoring-network-policy.yaml" ]; then
          echo "部署网络策略..."
          kubectl apply -f kubernetes/network-policies/monitoring-network-policy.yaml -n monitoring || echo "NetworkPolicy部署失败，跳过"
        fi
        
        # 部署Ingress资源 - 使用您本地的Ingress文件
        echo "部署Ingress资源..."
        kubectl apply -f kubernetes/ingress/ -n monitoring

    - name: Wait for ALB and get address
      id: get_elb
      run: |
        echo "等待ALB创建..."
        sleep 60
        
        # 检查所有资源状态
        echo "=== 检查部署状态 ==="
        kubectl get pods,svc,ingress -n monitoring
        
        # 获取ELB地址
        ELB_ADDRESS=$(kubectl get ingress -n monitoring -o jsonpath='{.items[0].status.loadBalancer.ingress[0].hostname}')
        
        if [ -z "$ELB_ADDRESS" ]; then
          echo "❌ 无法获取ELB地址，等待重试..."
          sleep 30
          ELB_ADDRESS=$(kubectl get ingress -n monitoring -o jsonpath='{.items[0].status.loadBalancer.ingress[0].hostname}')
        fi
        
        echo "ELB_ADDRESS=$ELB_ADDRESS" >> $GITHUB_OUTPUT
        echo "ELB地址: $ELB_ADDRESS"

    - name: Output access information
      run: |
        echo "=========================================="
        echo "🚀 监控栈部署完成！"
        echo "=========================================="
        echo ""
        echo "集群: ${{ env.CLUSTER_NAME }}"
        echo "区域: ${{ env.AWS_REGION }}"
        echo ""
        echo "使用以下URL访问监控面板："
        echo "📊 Prometheus: http://${{ steps.get_elb.outputs.ELB_ADDRESS }}/prometheus"
        echo "📈 Grafana: http://${{ steps.get_elb.outputs.ELB_ADDRESS }}/grafana"
        echo "🚨 Alertmanager: http://${{ steps.get_elb.outputs.ELB_ADDRESS }}/alertmanager"
        echo ""
        echo "如果路径访问有问题，请检查Ingress配置的路径规则"

    - name: Final verification
      run: |
        echo "=== 最终验证 ==="
        echo "=== Pod状态 ==="
        kubectl get pods -n monitoring -o wide
        echo ""
        echo "=== Node Exporter分布 ==="
        kubectl get pods -n monitoring -l app=node-exporter-limited -o wide
        echo ""
        echo "=== Ingress详情 ==="
        kubectl get ingress -n monitoring -o wide